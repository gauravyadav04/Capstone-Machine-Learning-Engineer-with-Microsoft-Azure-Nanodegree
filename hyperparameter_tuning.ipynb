{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment, Model\n",
        "from azureml.core.compute import AmlCompute\n",
        "from azureml.core.compute import ComputeTarget\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.sklearn import SKLearn\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.sampling import BayesianParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, choice\n",
        "import os\n",
        "import joblib"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1613063289603
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "experiment_name = 'hyperdrive_heart_failure_prediction'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)\n",
        "experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "Experiment(Name: hyperdrive_heart_failure_prediction,\nWorkspace: quick-starts-ws-138596)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>hyperdrive_heart_failure_prediction</td><td>quick-starts-ws-138596</td><td><a href=\"https://ml.azure.com/experiments/hyperdrive_heart_failure_prediction?wsid=/subscriptions/a0a76bad-11a1-4a2d-9887-97a29122c8ed/resourcegroups/aml-quickstarts-138596/workspaces/quick-starts-ws-138596\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1613063295595
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_cluster_name = \"capstone-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace = ws, name = compute_cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "    \n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',# for GPU, use \"STANDARD_NC6\"\n",
        "                                                           #vm_priority = 'lowpriority', # optional\n",
        "                                                           max_nodes=4)\n",
        "    compute_target = ComputeTarget.create(ws, compute_cluster_name, compute_config)\n",
        "    \n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count = 1, timeout_in_minutes = 10)\n",
        "# For a more detailed view of current AmlCompute status, use get_status()."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1613063303436
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598531923519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
        "early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval = 1, delay_evaluation = 5)\n",
        "\n",
        "# Create the different params that you will be using during training\n",
        "param_sampling = RandomParameterSampling({\n",
        "    \"--C\" : choice(0.01, 0.1, 1),\n",
        "    \"--max_iter\" : choice(50, 100, 150, 200)\n",
        "    })\n",
        "\n",
        "\n",
        "# Create your estimator and hyperdrive config\n",
        "\n",
        "# if \"training\" not in os.listdir():\n",
        "#     os.mkdir(\"./training\")\n",
        "    \n",
        "estimator = SKLearn(source_directory = '.', entry_script = 'train.py', compute_target = compute_cluster_name)\n",
        "\n",
        "hyperdrive_run_config = HyperDriveConfig(hyperparameter_sampling = param_sampling,\n",
        "                                     primary_metric_name = \"Accuracy\",\n",
        "                                     primary_metric_goal = PrimaryMetricGoal.MAXIMIZE,\n",
        "                                     max_total_runs = 10,\n",
        "                                     max_concurrent_runs = 4,\n",
        "                                     policy = early_termination_policy,\n",
        "                                     estimator = estimator)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'SKLearn' estimator is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or the AzureML-Tutorial curated environment.\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1613063310075
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "from azureml.core import Workspace\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, name='Heart_Failure_Clinical_Records_Dataset')\n",
        "\n",
        "df = dataset.to_pandas_dataframe()"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1613063325340
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n0  75.0        0                       582         0                 20   \n1  55.0        0                      7861         0                 38   \n2  65.0        0                       146         0                 20   \n3  50.0        1                       111         0                 20   \n4  65.0        1                       160         1                 20   \n\n   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n0                    1  265000.00               1.9           130    1   \n1                    0  263358.03               1.1           136    1   \n2                    0  162000.00               1.3           129    1   \n3                    0  210000.00               1.9           137    1   \n4                    0  327000.00               2.7           116    0   \n\n   smoking  time  DEATH_EVENT  \n0        0     4            1  \n1        0     6            1  \n2        1     7            1  \n3        0     7            1  \n4        0     8            1  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>anaemia</th>\n      <th>creatinine_phosphokinase</th>\n      <th>diabetes</th>\n      <th>ejection_fraction</th>\n      <th>high_blood_pressure</th>\n      <th>platelets</th>\n      <th>serum_creatinine</th>\n      <th>serum_sodium</th>\n      <th>sex</th>\n      <th>smoking</th>\n      <th>time</th>\n      <th>DEATH_EVENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>75.0</td>\n      <td>0</td>\n      <td>582</td>\n      <td>0</td>\n      <td>20</td>\n      <td>1</td>\n      <td>265000.00</td>\n      <td>1.9</td>\n      <td>130</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>55.0</td>\n      <td>0</td>\n      <td>7861</td>\n      <td>0</td>\n      <td>38</td>\n      <td>0</td>\n      <td>263358.03</td>\n      <td>1.1</td>\n      <td>136</td>\n      <td>1</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>65.0</td>\n      <td>0</td>\n      <td>146</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>162000.00</td>\n      <td>1.3</td>\n      <td>129</td>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>50.0</td>\n      <td>1</td>\n      <td>111</td>\n      <td>0</td>\n      <td>20</td>\n      <td>0</td>\n      <td>210000.00</td>\n      <td>1.9</td>\n      <td>137</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>65.0</td>\n      <td>1</td>\n      <td>160</td>\n      <td>1</td>\n      <td>20</td>\n      <td>0</td>\n      <td>327000.00</td>\n      <td>2.7</td>\n      <td>116</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1613063325625
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your experiment\n",
        "\n",
        "hyperdrive_run = experiment.submit(hyperdrive_run_config)\n",
        "\n",
        "RunDetails(hyperdrive_run).show()\n",
        "\n",
        "hyperdrive_run.get_status()\n",
        "\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c533a2455584d44a3754bc3bdd238bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Canceled\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/hyperdrive_heart_failure_prediction/runs/HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2?wsid=/subscriptions/a0a76bad-11a1-4a2d-9887-97a29122c8ed/resourcegroups/aml-quickstarts-138596/workspaces/quick-starts-ws-138596\", \"run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2\", \"run_properties\": {\"run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2\", \"created_utc\": \"2021-02-11T17:21:18.092818Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"9861499e-3c99-4ae2-be54-1ff13b085df2\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"10\", \"max_total_jobs\": \"10\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"policy_config\": \"{\\\"name\\\": \\\"BANDIT\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 5, \\\"slack_factor\\\": 0.1}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0.01, 0.1, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[50, 100, 150, 200]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--C\\\": [\\\"choice\\\", [[0.01, 0.1, 1]]], \\\"--max_iter\\\": [\\\"choice\\\", [[50, 100, 150, 200]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/a0a76bad-11a1-4a2d-9887-97a29122c8ed/resourceGroups/aml-quickstarts-138596/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-138596/experiments/hyperdrive_heart_failure_prediction\\\", \\\"SubscriptionId\\\": \\\"a0a76bad-11a1-4a2d-9887-97a29122c8ed\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-138596\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-138596\\\", \\\"ExperimentName\\\": \\\"hyperdrive_heart_failure_prediction\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"capstone-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"scikit-learn==0.20.3\\\", \\\"scipy==1.2.1\\\", \\\"joblib==0.13.2\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"9861499e-3c99-4ae2-be54-1ff13b085df2\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"d03a0305-8888-46c1-bfd3-4cf773b1f5df\\\", \\\"amlClientSessionId\\\": \\\"239aabba-e858-4d26-baef-dcac1e1f1135\\\", \\\"subscriptionId\\\": \\\"a0a76bad-11a1-4a2d-9887-97a29122c8ed\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 10, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/a0a76bad-11a1-4a2d-9887-97a29122c8ed/resourceGroups/aml-quickstarts-138596/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-138596/experiments/hyperdrive_heart_failure_prediction\\\", \\\"SubscriptionId\\\": \\\"a0a76bad-11a1-4a2d-9887-97a29122c8ed\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-138596\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-138596\\\", \\\"ExperimentName\\\": \\\"hyperdrive_heart_failure_prediction\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"capstone-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"scikit-learn==0.20.3\\\", \\\"scipy==1.2.1\\\", \\\"joblib==0.13.2\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"9861499e-3c99-4ae2-be54-1ff13b085df2\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"d03a0305-8888-46c1-bfd3-4cf773b1f5df\\\", \\\"amlClientSessionId\\\": \\\"239aabba-e858-4d26-baef-dcac1e1f1135\\\", \\\"subscriptionId\\\": \\\"a0a76bad-11a1-4a2d-9887-97a29122c8ed\\\", \\\"estimator\\\": \\\"SKLearn\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"Bandit\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 10, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"true\", \"cancellation_requested\": \"true\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-02-11T17:21:18.989557\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-02-11T17:21:18.989557\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"2496557f101c608f372ff5111afde37362e423c462984e782f8187c2f0ec0f55\\\"\", \"progress_metadata_digest\": \"\\\"2496557f101c608f372ff5111afde37362e423c462984e782f8187c2f0ec0f55\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-02-11T17:21:18.989557\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-02-11T17:21:18.989557\\\"\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 200}\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 200}\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 200}\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 200}\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 50}\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2\": \"{\\\"--C\\\": 0.1, \\\"--max_iter\\\": 50}\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 50}\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3\": \"{\\\"--C\\\": 0.01, \\\"--max_iter\\\": 50}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_preparation\", \"prepare_run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_preparation\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0_cancelled\": \"true\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0_cancelled\": \"true\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1_cancelled\": \"true\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1_cancelled\": \"true\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2_cancelled\": \"true\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2_cancelled\": \"true\", \"_aml_system_HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3_cancelled\": \"true\", \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3_cancelled\": \"true\"}, \"end_time_utc\": \"2021-02-11T17:24:54.354259Z\", \"status\": \"Canceled\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=tKp4QiKWEfRXxiLKcugdmrrl%2B5Y0vr8ENiq2v%2FgRRqQ%3D&st=2021-02-11T17%3A15%3A16Z&se=2021-02-12T01%3A25%3A16Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:03:36\", \"hyper_parameters\": {\"--C\": [\"choice\", [[0.01, 0.1, 1]]], \"--max_iter\": [\"choice\", [[50, 100, 150, 200]]]}}, \"child_runs\": [{\"run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3\", \"run_number\": 10, \"metric\": null, \"status\": \"Canceled\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-11T17:21:51.179545Z\", \"end_time\": \"2021-02-11T17:24:31.112819Z\", \"created_time\": \"2021-02-11T17:21:51.179545Z\", \"created_time_dt\": \"2021-02-11T17:21:51.179545Z\", \"duration\": \"0:02:39\", \"hyperdrive_id\": \"081e97b3-8e4e-422d-ad88-22e9ca785fc2\", \"arguments\": null, \"param_--C\": 0.01, \"param_--max_iter\": 50}, {\"run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1\", \"run_number\": 11, \"metric\": null, \"status\": \"Canceled\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-11T17:21:51.314571Z\", \"end_time\": \"2021-02-11T17:24:32.17944Z\", \"created_time\": \"2021-02-11T17:21:51.314571Z\", \"created_time_dt\": \"2021-02-11T17:21:51.314571Z\", \"duration\": \"0:02:40\", \"hyperdrive_id\": \"081e97b3-8e4e-422d-ad88-22e9ca785fc2\", \"arguments\": null, \"param_--C\": 0.01, \"param_--max_iter\": 200}, {\"run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0\", \"run_number\": 9, \"metric\": null, \"status\": \"Canceled\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-11T17:21:51.163072Z\", \"end_time\": \"2021-02-11T17:24:31.768313Z\", \"created_time\": \"2021-02-11T17:21:51.163072Z\", \"created_time_dt\": \"2021-02-11T17:21:51.163072Z\", \"duration\": \"0:02:40\", \"hyperdrive_id\": \"081e97b3-8e4e-422d-ad88-22e9ca785fc2\", \"arguments\": null, \"param_--C\": 0.1, \"param_--max_iter\": 200}, {\"run_id\": \"HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2\", \"run_number\": 12, \"metric\": null, \"status\": \"Canceled\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-02-11T17:21:51.434832Z\", \"end_time\": \"2021-02-11T17:24:31.517524Z\", \"created_time\": \"2021-02-11T17:21:51.434832Z\", \"created_time_dt\": \"2021-02-11T17:21:51.434832Z\", \"duration\": \"0:02:40\", \"hyperdrive_id\": \"081e97b3-8e4e-422d-ad88-22e9ca785fc2\", \"arguments\": null, \"param_--C\": 0.1, \"param_--max_iter\": 50}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-02-11T17:21:18.422218][API][INFO]Experiment created\\r\\n[2021-02-11T17:21:19.205752][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-02-11T17:21:19.5011169Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2021-02-11T17:21:19.533116][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-02-11T17:21:50.2952690Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2021-02-11T17:21:50.3196081Z][SCHEDULER][INFO]Scheduling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3'\\r\\n[2021-02-11T17:21:50.3311220Z][SCHEDULER][INFO]Scheduling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2'\\r\\n[2021-02-11T17:21:50.3142822Z][SCHEDULER][INFO]Scheduling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1'\\r\\n[2021-02-11T17:21:50.2959731Z][SCHEDULER][INFO]Scheduling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0'\\r\\n[2021-02-11T17:21:51.2681974Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0'\\r\\n[2021-02-11T17:21:51.3994753Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3'\\r\\n[2021-02-11T17:21:51.5376394Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1'\\r\\n[2021-02-11T17:21:51.6503327Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2'\\r\\n[2021-02-11T17:24:04.824929][API][INFO]Experiment has been marked as canceled by the user, all active/pending jobs will soon be terminated/canceled.\\r\\n[2021-02-11T17:24:04.752297][API][INFO]Processing cancellation request by the user.\\r\\n[2021-02-11T17:24:23.3983210Z][SCHEDULER][INFO]Cancelling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1'\\r\\n[2021-02-11T17:24:23.3998444Z][SCHEDULER][INFO]Cancelling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3'\\r\\n[2021-02-11T17:24:23.3989930Z][SCHEDULER][INFO]Cancelling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2'\\r\\n[2021-02-11T17:24:23.3975330Z][SCHEDULER][INFO]Cancelling job, id='HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0'\\r\\n[2021-02-11T17:24:24.056324][ENFORCER][INFO]Jobs [https://southcentralus.experiments.azureml.net/subscriptions/a0a76bad-11a1-4a2d-9887-97a29122c8ed/resourceGroups/aml-quickstarts-138596/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-138596/experiments/**SCRUBBED**/runs/HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0] do not contain any metrics with the primary metric name at this moment, policy cannot be applied.\\r\\n[2021-02-11T17:24:24.3189137Z][SCHEDULER][INFO]Updating job statuses to cancelled: [(job id = 'HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_0', previous status = 'SCHEDULED'), (job id = 'HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_1', previous status = 'SCHEDULED'), (job id = 'HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_2', previous status = 'SCHEDULED'), (job id = 'HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2_3', previous status = 'SCHEDULED')]\\r\\n[2021-02-11T17:24:54.833910][CONTROLLER][INFO]Experiment was 'ExperimentStatus.CANCEL_REQUESTED', is 'ExperimentStatus.CANCELLED'.\\r\\n[2021-02-11T17:24:55.710124][CONTROLLER][INFO]Experiment was 'ExperimentStatus.CANCEL_REQUESTED', is 'ExperimentStatus.CANCELLED'.\\n\\nError occurred: All child runs cancelled.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.20.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2\n",
            "Web View: https://ml.azure.com/experiments/hyperdrive_heart_failure_prediction/runs/HD_081e97b3-8e4e-422d-ad88-22e9ca785fc2?wsid=/subscriptions/a0a76bad-11a1-4a2d-9887-97a29122c8ed/resourcegroups/aml-quickstarts-138596/workspaces/quick-starts-ws-138596\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-02-11T17:21:18.422218][API][INFO]Experiment created<END>\\n\"\"<START>[2021-02-11T17:21:19.205752][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"<START>[2021-02-11T17:21:19.5011169Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\"<START>[2021-02-11T17:21:19.533116][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ExperimentExecutionException",
          "evalue": "ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    722\u001b[0m                     \u001b[0mwait_post_processing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_post_processing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m                     raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    724\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, file_handle, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mfile_handle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_before_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpoll_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# TODO use FileWatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mExperimentExecutionException\u001b[0m              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c2e3caf44b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mhyperdrive_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhyperdrive_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, wait_post_processing, raise_on_error)\u001b[0m\n\u001b[1;32m    729\u001b[0m                                 \u001b[0;34m\"https://aka.ms/aml-docs-cancel-run\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mExperimentExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mrunning_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRUNNING_STATES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mExperimentExecutionException\u001b[0m: ExperimentExecutionException:\n\tMessage: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"The output streaming for the run interrupted.\\nBut the run is still executing on the compute target. \\nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run\"\n    }\n}"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1613063703906
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your best run and save the model from that run.\n",
        "\n",
        "hyperdrive_best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "\n",
        "print('best run', hyperdrive_best_run)\n",
        "print('\\n Accuracy:', hyperdrive_best_run.get_metrics()['Accuracy'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best run Run(Experiment: hyperdrive_heart_failure_prediction,\n",
            "Id: HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed)\n",
            "\n",
            " Accuracy: 0.7833333333333333\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1613067404098
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(hyperdrive_best_run.get_details()['runDefinition']['arguments'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['--C', '1', '--max_iter', '100']\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1613067409859
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_best_run.get_details()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "{'runId': 'HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3',\n 'target': 'capstone-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2021-02-11T17:27:47.321797Z',\n 'endTimeUtc': '2021-02-11T17:43:39.814219Z',\n 'properties': {'_azureml.ComputeTargetType': 'amlcompute',\n  'ContentSnapshotId': '5112f466-7039-49f1-b014-73cd2bc99f5b',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'train.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--C', '1', '--max_iter', '100'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'capstone-cluster',\n  'dataReferences': {},\n  'data': {},\n  'outputData': {},\n  'jobName': None,\n  'maxRunDurationSeconds': None,\n  'nodeCount': 1,\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'Experiment hyperdrive_heart_failure_prediction Environment',\n   'version': 'Autosave_2021-02-11T17:08:54Z_f9b4b0fb',\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n     'dependencies': ['python=3.6.2',\n      {'pip': ['azureml-defaults',\n        'scikit-learn==0.20.3',\n        'scipy==1.2.1',\n        'joblib==0.13.2']}],\n     'name': 'azureml_ba9520bf386d662001eeb9523395794e'},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200423.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': True,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': 1},\n  'aiSuperComputer': {'instanceType': None,\n   'frameworkImage': None,\n   'imageVersion': None,\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': None, 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': True,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []}},\n 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_3d313af50efa4fb4e170c436ade5cba0fffaa0f7989fff06a198f45f14a5324a_d.txt': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/azureml-logs/55_azureml-execution-tvmps_3d313af50efa4fb4e170c436ade5cba0fffaa0f7989fff06a198f45f14a5324a_d.txt?sv=2019-02-02&sr=b&sig=mcG92igkF%2BwcXTx%2FkUxUGeF6QYcZbc3Atr6AnFmU%2BIg%3D&st=2021-02-11T18%3A05%3A41Z&se=2021-02-12T02%3A15%3A41Z&sp=r',\n  'azureml-logs/65_job_prep-tvmps_3d313af50efa4fb4e170c436ade5cba0fffaa0f7989fff06a198f45f14a5324a_d.txt': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/azureml-logs/65_job_prep-tvmps_3d313af50efa4fb4e170c436ade5cba0fffaa0f7989fff06a198f45f14a5324a_d.txt?sv=2019-02-02&sr=b&sig=5cKcLxImpbyBDtLXoCwRAzsvxYB5zWHb7bJWPcopf%2FY%3D&st=2021-02-11T18%3A05%3A41Z&se=2021-02-12T02%3A15%3A41Z&sp=r',\n  'azureml-logs/70_driver_log.txt': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=YSclu889P7Hiv3TioLWRPwVUmvFIsZFAqrMeiAglbgw%3D&st=2021-02-11T18%3A05%3A41Z&se=2021-02-12T02%3A15%3A41Z&sp=r',\n  'azureml-logs/75_job_post-tvmps_3d313af50efa4fb4e170c436ade5cba0fffaa0f7989fff06a198f45f14a5324a_d.txt': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/azureml-logs/75_job_post-tvmps_3d313af50efa4fb4e170c436ade5cba0fffaa0f7989fff06a198f45f14a5324a_d.txt?sv=2019-02-02&sr=b&sig=u1b96D2l5%2BGY14M7AiARYeAs0fq2YPl%2BcBNoJ1ZP%2BKA%3D&st=2021-02-11T18%3A05%3A41Z&se=2021-02-12T02%3A15%3A41Z&sp=r',\n  'azureml-logs/process_info.json': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=d8jxY1oYOXo2xU6uO2%2F4XKAc7TBv1cNGUplXmzMlU0Y%3D&st=2021-02-11T18%3A05%3A41Z&se=2021-02-12T02%3A15%3A41Z&sp=r',\n  'azureml-logs/process_status.json': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=ZjKs0dbXhffTs0egiVl2He39QA4G15u1rzUd5Cvmkig%3D&st=2021-02-11T18%3A05%3A41Z&se=2021-02-12T02%3A15%3A41Z&sp=r',\n  'logs/azureml/103_azureml.log': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/logs/azureml/103_azureml.log?sv=2019-02-02&sr=b&sig=4odgo%2ByjhZl4nHspHioPwtx%2FV%2BpiVdP5yOxGuvGWMRg%3D&st=2021-02-11T18%3A05%3A40Z&se=2021-02-12T02%3A15%3A40Z&sp=r',\n  'logs/azureml/dataprep/backgroundProcess.log': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=LPTRjVEpkRUuR20FtXmgaQQ%2BfBB7UOGy%2FTDMkuxLiQE%3D&st=2021-02-11T18%3A05%3A40Z&se=2021-02-12T02%3A15%3A40Z&sp=r',\n  'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=3LzuJHgx%2FK7tdtC47%2BUb6BtbTAUP%2FKS5%2BkyrPXOP6N4%3D&st=2021-02-11T18%3A05%3A40Z&se=2021-02-12T02%3A15%3A40Z&sp=r',\n  'logs/azureml/job_prep_azureml.log': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=7dFqxKus2wEhVSGMM4eksrgpP4ipSWo6QcsCXLbzGmk%3D&st=2021-02-11T18%3A05%3A40Z&se=2021-02-12T02%3A15%3A40Z&sp=r',\n  'logs/azureml/job_release_azureml.log': 'https://mlstrg138596.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c29a7f8e-cd51-4779-99d4-d2220f403c68_3/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=MsDxnuaG5dRVWgsbyucfcUT6aPpyPOY97r169Ur7q%2Fk%3D&st=2021-02-11T18%3A05%3A40Z&se=2021-02-12T02%3A15%3A40Z&sp=r'},\n 'submittedBy': 'ODL_User 138596'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1613067414599
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_values = hyperdrive_best_run.get_details()['runDefinition']['arguments']\n",
        "\n",
        "os.makedirs('output', exist_ok=True)\n",
        "\n",
        "joblib.dump(parameter_values, filename='output/best-hyperdrive.pkl')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "['output/best-hyperdrive.pkl']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1613067491551
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model.register(workspace = ws, model_name ='best-hyperdrive',\n",
        "                       model_path = './output/best-hyperdrive.pkl',\n",
        "                       tags = {'Method' : 'HyperDrive'},\n",
        "                       properties={'Accuracy': hyperdrive_best_run.get_metrics()['Accuracy']})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model best-hyperdrive\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1613067510519
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}